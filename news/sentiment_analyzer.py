# sentiment_analyzer.py
# ä½¿ç”¨Hugging Faceé¢„è®­ç»ƒæ¨¡åž‹è¿›è¡Œæƒ…æ„Ÿåˆ†æž

from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
import torch
import pandas as pd

class SentimentAnalyzer:
    def __init__(self, model_name="ProsusAI/finbert"):
        """
        åˆå§‹åŒ–æƒ…æ„Ÿåˆ†æžå™¨
        model_name: é¢„è®­ç»ƒæ¨¡åž‹åç§°
        """
        self.model_name = model_name
        self.analyzer = None
        self.tokenizer = None
        self.model = None
        
    def load_model(self):
        """åŠ è½½é¢„è®­ç»ƒæ¨¡åž‹"""
        try:
            print(f"ðŸ”„ æ­£åœ¨åŠ è½½æ¨¡åž‹: {self.model_name}")
            
            # ä½¿ç”¨pipelineæ–¹å¼ï¼ˆæœ€ç®€å•ï¼‰
            self.analyzer = pipeline(
                "sentiment-analysis",
                model=self.model_name,
                tokenizer=self.model_name
            )
            
            print("âœ… æ¨¡åž‹åŠ è½½æˆåŠŸï¼")
            return True
            
        except Exception as e:
            print(f"âŒ æ¨¡åž‹åŠ è½½å¤±è´¥: {e}")
            return False
    
    def analyze_text(self, text):
        """åˆ†æžå•ä¸ªæ–‡æœ¬çš„æƒ…æ„Ÿ"""
        if not self.analyzer:
            print("âŒ æ¨¡åž‹æœªåŠ è½½ï¼Œè¯·å…ˆè°ƒç”¨ load_model()")
            return None
        
        try:
            # é™åˆ¶æ–‡æœ¬é•¿åº¦ï¼ˆé¿å…tokenè¿‡é•¿ï¼‰
            if len(text) > 500:
                text = text[:500] + "..."
            
            result = self.analyzer(text)
            return result[0]
            
        except Exception as e:
            print(f"âŒ åˆ†æžå¤±è´¥: {e}")
            return None
    
    def analyze_news_batch(self, news_list):
        """æ‰¹é‡åˆ†æžæ–°é—»æƒ…æ„Ÿ"""
        if not self.analyzer:
            print("âŒ æ¨¡åž‹æœªåŠ è½½ï¼Œè¯·å…ˆè°ƒç”¨ load_model()")
            return []
        
        results = []
        
        for i, news in enumerate(news_list):
            print(f"ðŸ“Š æ­£åœ¨åˆ†æžç¬¬ {i+1}/{len(news_list)} æ¡æ–°é—»...")
            
            # åˆ†æžæ ‡é¢˜å’Œæ‘˜è¦
            title_sentiment = self.analyze_text(news.get('title', ''))
            summary_sentiment = self.analyze_text(news.get('summary', ''))
            
            # ç»¼åˆæƒ…æ„Ÿï¼ˆç®€å•å¹³å‡ï¼‰
            combined_sentiment = self._combine_sentiments(title_sentiment, summary_sentiment)
            
            results.append({
                'ticker': news.get('ticker', ''),
                'title': news.get('title', ''),
                'title_sentiment': title_sentiment,
                'summary_sentiment': summary_sentiment,
                'combined_sentiment': combined_sentiment
            })
        
        return results
    
    def _combine_sentiments(self, title_sent, summary_sent):
        """åˆå¹¶æ ‡é¢˜å’Œæ‘˜è¦çš„æƒ…æ„Ÿ"""
        if not title_sent and not summary_sent:
            return {'label': 'neutral', 'score': 0.5}
        
        # ç®€å•çš„æƒ…æ„Ÿåˆå¹¶é€»è¾‘
        sentiments = []
        if title_sent:
            sentiments.append(title_sent)
        if summary_sent:
            sentiments.append(summary_sent)
        
        # è®¡ç®—å¹³å‡æƒ…æ„Ÿ
        avg_score = sum(s['score'] for s in sentiments) / len(sentiments)
        
        # æ ¹æ®åˆ†æ•°ç¡®å®šæ ‡ç­¾
        if avg_score > 0.6:
            label = 'positive'
        elif avg_score < 0.4:
            label = 'negative'
        else:
            label = 'neutral'
        
        return {'label': label, 'score': avg_score}
    
    def save_results(self, results, output_file="news/sentiment_analysis.csv"):
        """ä¿å­˜æƒ…æ„Ÿåˆ†æžç»“æžœ"""
        try:
            df = pd.DataFrame(results)
            df.to_csv(output_file, index=False, encoding='utf-8')
            print(f"âœ… æƒ…æ„Ÿåˆ†æžç»“æžœå·²ä¿å­˜åˆ°: {output_file}")
            
            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            if not df.empty:
                print("\nðŸ“Š æƒ…æ„Ÿåˆ†æžç»Ÿè®¡:")
                sentiment_counts = df['combined_sentiment'].apply(lambda x: x['label'] if isinstance(x, dict) else 'unknown').value_counts()
                for sentiment, count in sentiment_counts.items():
                    print(f"  {sentiment}: {count} æ¡")
        
        except Exception as e:
            print(f"âŒ ä¿å­˜å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨"""
    
    # åˆ›å»ºæƒ…æ„Ÿåˆ†æžå™¨
    analyzer = SentimentAnalyzer("ProsusAI/finbert")
    
    # åŠ è½½æ¨¡åž‹
    if not analyzer.load_model():
        return
    
    # æµ‹è¯•æ–‡æœ¬
    test_texts = [
        "Apple reports record-breaking quarterly earnings, exceeding analyst expectations",
        "Tesla stock plunges after disappointing delivery numbers",
        "Market remains stable as investors await Fed decision",
        "Company announces major layoffs and restructuring plan",
        "Innovative product launch drives strong customer adoption"
    ]
    
    print("\nðŸ§ª æµ‹è¯•æƒ…æ„Ÿåˆ†æž:")
    for i, text in enumerate(test_texts, 1):
        result = analyzer.analyze_text(text)
        if result:
            print(f"  {i}. {text[:50]}...")
            print(f"     æƒ…æ„Ÿ: {result['label']} (ç½®ä¿¡åº¦: {result['score']:.3f})")
    
    # å¦‚æžœæœ‰æ–°é—»æ•°æ®ï¼Œå¯ä»¥åˆ†æžæ–°é—»
    try:
        news_df = pd.read_csv("news/holdings_news.csv")
        if not news_df.empty:
            print(f"\nðŸ“° åˆ†æž {len(news_df)} æ¡æ–°é—»çš„æƒ…æ„Ÿ...")
            news_list = news_df.to_dict('records')
            results = analyzer.analyze_news_batch(news_list)
            analyzer.save_results(results)
    except FileNotFoundError:
        print("ðŸ“ æœªæ‰¾åˆ°æ–°é—»æ–‡ä»¶ï¼Œè·³è¿‡æ–°é—»åˆ†æž")

if __name__ == "__main__":
    main() 