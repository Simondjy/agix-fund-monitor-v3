#!/usr/bin/env python3
"""
æ•°æ®åŒæ­¥è„šæœ¬
ç”¨äºäº‘ç«¯éƒ¨ç½²æ—¶çš„æ•°æ®ç®¡ç†å’ŒåŒæ­¥
"""

import os
import sys
import json
import requests
import pandas as pd
from pathlib import Path
from datetime import datetime, timedelta
import argparse

class DataSync:
    def __init__(self, data_dir="data"):
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(exist_ok=True)
        
    def save_data_to_json(self, data, filename):
        """å°†æ•°æ®ä¿å­˜ä¸ºJSONæ ¼å¼"""
        filepath = self.data_dir / filename
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2, default=str)
        print(f"âœ… æ•°æ®å·²ä¿å­˜: {filepath}")
        
    def load_data_from_json(self, filename):
        """ä»JSONæ–‡ä»¶åŠ è½½æ•°æ®"""
        filepath = self.data_dir / filename
        if filepath.exists():
            with open(filepath, 'r', encoding='utf-8') as f:
                return json.load(f)
        return None
        
    def convert_csv_to_json(self, csv_path, json_filename):
        """å°†CSVæ–‡ä»¶è½¬æ¢ä¸ºJSONæ ¼å¼"""
        if not Path(csv_path).exists():
            print(f"âŒ CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_path}")
            return False
            
        try:
            df = pd.read_csv(csv_path)
            data = {
                'columns': df.columns.tolist(),
                'data': df.values.tolist(),
                'index': df.index.tolist() if df.index.name else None,
                'last_updated': datetime.now().isoformat()
            }
            self.save_data_to_json(data, json_filename)
            return True
        except Exception as e:
            print(f"âŒ è½¬æ¢å¤±è´¥: {e}")
            return False
            
    def convert_json_to_csv(self, json_filename, csv_path):
        """å°†JSONæ ¼å¼æ•°æ®è½¬æ¢å›CSV"""
        data = self.load_data_from_json(json_filename)
        if not data:
            print(f"âŒ JSONæ–‡ä»¶ä¸å­˜åœ¨: {json_filename}")
            return False
            
        try:
            df = pd.DataFrame(data['data'], columns=data['columns'])
            if data['index']:
                df.index = data['index']
            df.to_csv(csv_path, index=True)
            print(f"âœ… CSVæ–‡ä»¶å·²ç”Ÿæˆ: {csv_path}")
            return True
        except Exception as e:
            print(f"âŒ è½¬æ¢å¤±è´¥: {e}")
            return False
            
    def sync_all_data(self):
        """åŒæ­¥æ‰€æœ‰æ•°æ®æ–‡ä»¶"""
        print("ğŸ”„ å¼€å§‹åŒæ­¥æ‰€æœ‰æ•°æ®æ–‡ä»¶...")
        
        # éœ€è¦åŒæ­¥çš„æ–‡ä»¶åˆ—è¡¨
        files_to_sync = [
            ('source_data/market_data_closes.csv', 'market_data_closes.json'),
            ('source_data/market_data_volumes.csv', 'market_data_volumes.json'),
            ('source_data/holdings_tickers.csv', 'holdings_tickers.json'),
            ('source_data/holdings_info.csv', 'holdings_info.json'),
            ('processed_data/returns.csv', 'returns.json'),
            ('processed_data/risk_metrics.csv', 'risk_metrics.json'),
            ('processed_data/volume_analysis.csv', 'volume_analysis.json'),
            ('processed_data/holdings_sectorAnalysis.csv', 'holdings_sectorAnalysis.json'),
            ('processed_data/holdings_countryAnalysis.csv', 'holdings_countryAnalysis.json')
        ]
        
        success_count = 0
        for csv_path, json_filename in files_to_sync:
            if self.convert_csv_to_json(csv_path, json_filename):
                success_count += 1
                
        print(f"âœ… åŒæ­¥å®Œæˆ: {success_count}/{len(files_to_sync)} ä¸ªæ–‡ä»¶")
        return success_count == len(files_to_sync)
        
    def restore_all_data(self):
        """æ¢å¤æ‰€æœ‰æ•°æ®æ–‡ä»¶"""
        print("ğŸ”„ å¼€å§‹æ¢å¤æ‰€æœ‰æ•°æ®æ–‡ä»¶...")
        
        # éœ€è¦æ¢å¤çš„æ–‡ä»¶åˆ—è¡¨
        files_to_restore = [
            ('market_data_closes.json', 'source_data/market_data_closes.csv'),
            ('market_data_volumes.json', 'source_data/market_data_volumes.csv'),
            ('holdings_tickers.json', 'source_data/holdings_tickers.csv'),
            ('holdings_info.json', 'source_data/holdings_info.csv'),
            ('returns.json', 'processed_data/returns.csv'),
            ('risk_metrics.json', 'processed_data/risk_metrics.csv'),
            ('volume_analysis.json', 'processed_data/volume_analysis.csv'),
            ('holdings_sectorAnalysis.json', 'processed_data/holdings_sectorAnalysis.csv'),
            ('holdings_countryAnalysis.json', 'processed_data/holdings_countryAnalysis.csv')
        ]
        
        # åˆ›å»ºå¿…è¦çš„ç›®å½•
        Path('source_data').mkdir(exist_ok=True)
        Path('processed_data').mkdir(exist_ok=True)
        
        success_count = 0
        for json_filename, csv_path in files_to_restore:
            if self.convert_json_to_csv(json_filename, csv_path):
                success_count += 1
                
        print(f"âœ… æ¢å¤å®Œæˆ: {success_count}/{len(files_to_restore)} ä¸ªæ–‡ä»¶")
        return success_count == len(files_to_restore)
        
    def upload_to_cloud_storage(self, bucket_name, credentials_file=None):
        """ä¸Šä¼ æ•°æ®åˆ°äº‘å­˜å‚¨ï¼ˆç¤ºä¾‹ï¼šAWS S3ï¼‰"""
        try:
            import boto3
            from botocore.exceptions import NoCredentialsError
            
            if credentials_file:
                session = boto3.Session(profile_name=credentials_file)
                s3 = session.client('s3')
            else:
                s3 = boto3.client('s3')
                
            # ä¸Šä¼ æ‰€æœ‰JSONæ–‡ä»¶
            for json_file in self.data_dir.glob('*.json'):
                s3.upload_file(
                    str(json_file), 
                    bucket_name, 
                    f"agix-monitor-data/{json_file.name}"
                )
                print(f"âœ… å·²ä¸Šä¼ : {json_file.name}")
                
            return True
        except ImportError:
            print("âŒ éœ€è¦å®‰è£… boto3: pip install boto3")
            return False
        except NoCredentialsError:
            print("âŒ éœ€è¦é…ç½®AWSå‡­è¯")
            return False
        except Exception as e:
            print(f"âŒ ä¸Šä¼ å¤±è´¥: {e}")
            return False
            
    def download_from_cloud_storage(self, bucket_name, credentials_file=None):
        """ä»äº‘å­˜å‚¨ä¸‹è½½æ•°æ®"""
        try:
            import boto3
            from botocore.exceptions import NoCredentialsError
            
            if credentials_file:
                session = boto3.Session(profile_name=credentials_file)
                s3 = session.client('s3')
            else:
                s3 = boto3.client('s3')
                
            # åˆ—å‡ºæ‰€æœ‰JSONæ–‡ä»¶
            response = s3.list_objects_v2(
                Bucket=bucket_name,
                Prefix="agix-monitor-data/"
            )
            
            if 'Contents' in response:
                for obj in response['Contents']:
                    if obj['Key'].endswith('.json'):
                        filename = obj['Key'].split('/')[-1]
                        s3.download_file(
                            bucket_name, 
                            obj['Key'], 
                            str(self.data_dir / filename)
                        )
                        print(f"âœ… å·²ä¸‹è½½: {filename}")
                        
            return True
        except ImportError:
            print("âŒ éœ€è¦å®‰è£… boto3: pip install boto3")
            return False
        except NoCredentialsError:
            print("âŒ éœ€è¦é…ç½®AWSå‡­è¯")
            return False
        except Exception as e:
            print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
            return False

def main():
    parser = argparse.ArgumentParser(description="AGIX Fund Monitor æ•°æ®åŒæ­¥å·¥å…·")
    parser.add_argument("--action", choices=["sync", "restore", "upload", "download"], 
                       required=True, help="æ‰§è¡Œçš„æ“ä½œ")
    parser.add_argument("--data-dir", default="data", help="æ•°æ®ç›®å½•")
    parser.add_argument("--bucket", help="äº‘å­˜å‚¨æ¡¶åç§°")
    parser.add_argument("--credentials", help="AWSå‡­è¯æ–‡ä»¶")
    
    args = parser.parse_args()
    
    sync = DataSync(args.data_dir)
    
    if args.action == "sync":
        sync.sync_all_data()
    elif args.action == "restore":
        sync.restore_all_data()
    elif args.action == "upload":
        if not args.bucket:
            print("âŒ éœ€è¦æŒ‡å®š --bucket å‚æ•°")
            sys.exit(1)
        sync.upload_to_cloud_storage(args.bucket, args.credentials)
    elif args.action == "download":
        if not args.bucket:
            print("âŒ éœ€è¦æŒ‡å®š --bucket å‚æ•°")
            sys.exit(1)
        sync.download_from_cloud_storage(args.bucket, args.credentials)

if __name__ == "__main__":
    main() 