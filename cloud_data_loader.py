"""
äº‘ç«¯æ•°æ®åŠ è½½æ¨¡å—
ç”¨äºåœ¨äº‘ç«¯éƒ¨ç½²ç¯å¢ƒä¸­åŠ è½½å’Œç®¡ç†æ•°æ®
"""

import os
import json
import pandas as pd
from pathlib import Path
from datetime import datetime
import streamlit as st

class CloudDataLoader:
    def __init__(self, data_dir="data"):
        self.data_dir = Path(data_dir)
        self.cache = {}
        
    def load_json_data(self, filename):
        """ä»JSONæ–‡ä»¶åŠ è½½æ•°æ®"""
        filepath = self.data_dir / filename
        
        if filename in self.cache:
            return self.cache[filename]
            
        if not filepath.exists():
            st.error(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {filename}")
            return None
            
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)
                
            # è½¬æ¢ä¸ºDataFrame
            df = pd.DataFrame(data['data'], columns=data['columns'])
            if data['index']:
                df.index = data['index']
            
            # å¯¹äºå¸‚åœºæ•°æ®æ–‡ä»¶ï¼Œç¡®ä¿æ•°å€¼åˆ—è¢«æ­£ç¡®è½¬æ¢ä¸ºæ•°å€¼ç±»å‹
            if 'market_data_closes' in filename or 'market_data_volumes' in filename:
                # å°†Dateåˆ—è®¾ç½®ä¸ºç´¢å¼•
                if 'Date' in df.columns:
                    df['Date'] = pd.to_datetime(df['Date'])
                    df.set_index('Date', inplace=True)
                
                # å°†æ‰€æœ‰æ•°å€¼åˆ—è½¬æ¢ä¸ºfloatç±»å‹
                numeric_columns = df.select_dtypes(include=['object']).columns
                for col in numeric_columns:
                    df[col] = pd.to_numeric(df[col], errors='coerce')
                
            self.cache[filename] = df
            return df
        except Exception as e:
            st.error(f"åŠ è½½æ•°æ®å¤±è´¥ {filename}: {e}")
            return None
            
    def load_all_data(self):
        """åŠ è½½æ‰€æœ‰å¿…è¦çš„æ•°æ®æ–‡ä»¶"""
        data_files = {
            'returns': 'returns.json',
            'risk_metrics': 'risk_metrics.json', 
            'volume_analysis': 'volume_analysis.json',
            'market_closes': 'market_data_closes.json',
            'market_volumes': 'market_data_volumes.json',
            'holdings_tickers': 'holdings_tickers.json',
            'holdings_info': 'holdings_info.json',
            'sector_analysis': 'holdings_sectorAnalysis.json',
            'country_analysis': 'holdings_countryAnalysis.json'
        }
        
        data = {}
        for key, filename in data_files.items():
            df = self.load_json_data(filename)
            if df is not None:
                data[key] = df
                
        return data
        
    def get_data_status(self):
        """è·å–æ•°æ®çŠ¶æ€ä¿¡æ¯"""
        status = {}
        data_files = [
            'returns.json', 'risk_metrics.json', 'volume_analysis.json',
            'market_data_closes.json', 'market_data_volumes.json',
            'holdings_tickers.json', 'holdings_info.json',
            'holdings_sectorAnalysis.json', 'holdings_countryAnalysis.json'
        ]
        
        for filename in data_files:
            filepath = self.data_dir / filename
            if filepath.exists():
                # è·å–æ–‡ä»¶ä¿®æ”¹æ—¶é—´
                mtime = datetime.fromtimestamp(filepath.stat().st_mtime)
                status[filename] = {
                    'exists': True,
                    'last_modified': mtime.strftime('%Y-%m-%d %H:%M:%S'),
                    'size': filepath.stat().st_size
                }
            else:
                status[filename] = {'exists': False}
                
        return status

# å…¨å±€æ•°æ®åŠ è½½å™¨å®ä¾‹
@st.cache_resource
def get_data_loader():
    """è·å–æ•°æ®åŠ è½½å™¨å®ä¾‹ï¼ˆä½¿ç”¨Streamlitç¼“å­˜ï¼‰"""
    return CloudDataLoader()

def load_application_data():
    """åŠ è½½åº”ç”¨æ‰€éœ€çš„æ‰€æœ‰æ•°æ®"""
    loader = get_data_loader()
    data = loader.load_all_data()
    
    # æ£€æŸ¥å¿…è¦çš„æ•°æ®æ˜¯å¦å­˜åœ¨
    required_data = ['returns', 'risk_metrics', 'volume_analysis', 'market_closes', 'market_volumes']
    missing_data = [key for key in required_data if key not in data]
    
    if missing_data:
        st.error(f"ç¼ºå°‘å¿…è¦çš„æ•°æ®æ–‡ä»¶: {missing_data}")
        st.info("è¯·ç¡®ä¿æ•°æ®æ–‡ä»¶å·²æ­£ç¡®ä¸Šä¼ åˆ°äº‘ç«¯")
        return None
        
    return data

def display_data_status():
    """æ˜¾ç¤ºæ•°æ®çŠ¶æ€"""
    loader = get_data_loader()
    status = loader.get_data_status()
    
    st.subheader("ğŸ“Š æ•°æ®çŠ¶æ€")
    
    # ç»Ÿè®¡ä¿¡æ¯
    total_files = len(status)
    existing_files = sum(1 for info in status.values() if info['exists'])
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("æ€»æ–‡ä»¶æ•°", total_files)
    with col2:
        st.metric("å¯ç”¨æ–‡ä»¶æ•°", existing_files)
    with col3:
        st.metric("å®Œæ•´åº¦", f"{existing_files/total_files*100:.1f}%")
    
    # è¯¦ç»†çŠ¶æ€
    with st.expander("æŸ¥çœ‹è¯¦ç»†çŠ¶æ€"):
        for filename, info in status.items():
            if info['exists']:
                st.success(f"âœ… {filename} - {info['last_modified']} ({info['size']} bytes)")
            else:
                st.error(f"âŒ {filename} - æ–‡ä»¶ä¸å­˜åœ¨")

# å…¼å®¹æ€§å‡½æ•°ï¼Œç”¨äºæ›¿æ¢åŸæœ‰çš„æ•°æ®åŠ è½½é€»è¾‘
def load_returns_data():
    """åŠ è½½æ”¶ç›Šç‡æ•°æ®"""
    loader = get_data_loader()
    return loader.load_json_data('returns.json')

def load_risk_metrics_data():
    """åŠ è½½é£é™©æŒ‡æ ‡æ•°æ®"""
    loader = get_data_loader()
    return loader.load_json_data('risk_metrics.json')

def load_volume_analysis_data():
    """åŠ è½½æˆäº¤é‡åˆ†ææ•°æ®"""
    loader = get_data_loader()
    return loader.load_json_data('volume_analysis.json')

def load_market_closes_data():
    """åŠ è½½æ”¶ç›˜ä»·æ•°æ®"""
    loader = get_data_loader()
    return loader.load_json_data('market_data_closes.json')

def load_market_volumes_data():
    """åŠ è½½æˆäº¤é‡æ•°æ®"""
    loader = get_data_loader()
    return loader.load_json_data('market_data_volumes.json')

def load_sector_analysis_data():
    """åŠ è½½è¡Œä¸šåˆ†ææ•°æ®"""
    loader = get_data_loader()
    return loader.load_json_data('holdings_sectorAnalysis.json')

def load_country_analysis_data():
    """åŠ è½½å›½å®¶åˆ†ææ•°æ®"""
    loader = get_data_loader()
    return loader.load_json_data('holdings_countryAnalysis.json') 